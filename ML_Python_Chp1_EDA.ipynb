{"cells":[{"cell_type":"markdown","source":["[source](https://google.com)"],"metadata":{}},{"cell_type":"markdown","source":["# Feature Engineering\n\nPrediction quality of any machine learning algorithm depends predominantly on the quality of input being passed\n\nProcess of creating appropriate data features by applying business context is called **feature engineering**\n\n## Dealing with missing values\n\nMissing data can mislead or create problems for analyzing the data\n\nIn order to avoid any such issues, you need to impute missing data \n\nThere are four most commonly used techniques for data imputation\n\n1. Delete\n2. Replace with summary\n3. Random replace\n4. Using predictive model"],"metadata":{}},{"cell_type":"code","source":["from numpy import nan\nimport pandas as pd\ndata = {'A':[2,nan,nan,10,10,10],'B':[6,6,6,10,10,10],'C':[nan,2,nan,10,10,10]}\ndf = pd.DataFrame(data,columns=['A','B','C'])\ndf"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.0</td>\n      <td>6</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>6</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>6</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10.0</td>\n      <td>10</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10.0</td>\n      <td>10</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>10.0</td>\n      <td>10</td>\n      <td>10.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":3},{"cell_type":"markdown","source":["### Delete\nDelete the rows containing missing values\n\nSuitable and effective when the number of missing value rows count is insignificant (say < 5%) compare to the overall record count\n\n`dropna()` function in Pandas"],"metadata":{}},{"cell_type":"code","source":["df.dropna()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>10.0</td>\n      <td>10</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10.0</td>\n      <td>10</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>10.0</td>\n      <td>10</td>\n      <td>10.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":5},{"cell_type":"markdown","source":["### Replace with summary: \nMost commonly used imputation technique\n\nFor **continuous or quantitative** variables, either mean/average or mode or median value of the respective column can be used to replace the missing values\n\nFor **categorical or qualitative** variables, the mode (most frequent) summation technique works better\n\n`fillna()` function in Pandas"],"metadata":{}},{"cell_type":"code","source":["df.fillna(df.mean())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.0</td>\n      <td>6</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8.0</td>\n      <td>6</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8.0</td>\n      <td>6</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10.0</td>\n      <td>10</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10.0</td>\n      <td>10</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>10.0</td>\n      <td>10</td>\n      <td>10.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["## Handling Categorical Data\nMost of the machine’s learning libraries are designed to work well with numerical variables. \n\nSo categorical variables in their original form of text description can’t be directly used for model building."],"metadata":{}},{"cell_type":"markdown","source":["###Create dummy variable: \nThis is a Boolean variable that indicates the presence of a category with the value 1 and 0 for absence\n\nYou should create **k-1** dummy variables, where **k** is the number of levels \n\nPandas provides a useful function *‘get_dummies’* to create a dummy variable for a given categorical variable"],"metadata":{}},{"cell_type":"code","source":["import pandas as pd\nfrom patsy import dmatrices\ndf = pd.DataFrame({'A': ['high', 'medium', 'low'],\n 'B': [10,20,30]},\n index=[0, 1, 2])\ndf"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A</th>\n      <th>B</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>high</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>medium</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>low</td>\n      <td>30</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["# Create dummy varables\npd.get_dummies(df, prefix='A', columns=['A'])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>B</th>\n      <th>A_high</th>\n      <th>A_low</th>\n      <th>A_medium</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>30</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":11},{"cell_type":"markdown","source":["## Normalizing Data\nA unit or scale of measurement for different variables varies, so an analysis with the raw measurement could be artificially skewed toward the variables with higher absolute values\n\nBringing all the different types of variable units in the same order of magnitude thus eliminates the potential outlier measurements that would misrepresent the finding and negatively affect the accuracy of the conclusion \n\nTwo broadly used methods for rescaling data are **normalization** and **standardization**.\n\nNormalizing data can be achieved by *Min-Max* scaling; the formula is given below, which will scale all numeric values in the range 0 to 1.\n\n$$(X{_n}{_o}{_r}{_m}=(X-X{_m}{_i}{_n})/(X{_m}{_a}{_x}-X{_m}{_i}{_n}))$$\n\n> Ensure you remove extreme outliers before applying the above technique as it can skew the normal values in your data to a small interval\n\nThe standardization technique will transform the variables to have a zero mean and standard deviation of one. The formula for standardization is given below and the outcome is commonly known as z-scores.\n\n$$(Z=(X-\\mu)/\\sigma)$$\n\nWhere μ is the mean and σ is the standard deviation.\nStandardization has often been the preferred method for various analysis as it tells us where each data point lies within its distribution and a rough indication of outliers."],"metadata":{}},{"cell_type":"code","source":["from sklearn import datasets\nimport numpy as np\nfrom sklearn import preprocessing\niris = datasets.load_iris()\nX = iris.data[:, [2, 3]]\ny = iris.target\nstd_scale = preprocessing.StandardScaler().fit(X)\nX_std = std_scale.transform(X)\nminmax_scale = preprocessing.MinMaxScaler().fit(X)\nX_minmax = minmax_scale.transform(X)\n\nprint('Mean before standardization: petal length={:.1f}, petal width={:.1f}'\n .format(X[:,0].mean(), X[:,1].mean()))\nprint('SD before standardization: petal length={:.1f}, petal width={:.1f}'\n .format(X[:,0].std(), X[:,1].std()))\nprint('Mean after standardization: petal length={:.1f}, petal width={:.1f}'\n .format(X_std[:,0].mean(), X_std[:,1].mean()))\nprint('SD after standardization: petal length={:.1f}, petal width={:.1f}'\n .format(X_std[:,0].std(), X_std[:,1].std()))\nprint('\\nMin value before min-max scaling: patel length={:.1f}, patel width={:.1f}'\n .format(X[:,0].min(), X[:,1].min()))\nprint('Max value before min-max scaling: petal length={:.1f}, petal width={:.1f}'\n .format(X[:,0].max(), X[:,1].max()))\nprint('Min value after min-max scaling: patel length={:.1f}, patel width={:.1f}'\n .format(X_minmax[:,0].min(), X_minmax[:,1].min()))\nprint('Max value after min-max scaling: petal length={:.1f}, petal width={:.1f}'\n .format(X_minmax[:,0].max(), X_minmax[:,1].max()))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":13},{"cell_type":"code","source":["from sklearn import datasets\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\niris = datasets.load_iris()\n# Let's convert to dataframe\niris = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n columns= iris['feature_names'] + ['species'])\n# replace the values with class labels\niris.species = np.where(iris.species == 0.0, 'setosa', np.where(iris.\nspecies==1.0,'versicolor', 'virginica'))\n# let's remove spaces from column name\niris.columns = iris.columns.str.replace(' ','')\niris.describe()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepallength(cm)</th>\n      <th>sepalwidth(cm)</th>\n      <th>petallength(cm)</th>\n      <th>petalwidth(cm)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>150.000000</td>\n      <td>150.000000</td>\n      <td>150.000000</td>\n      <td>150.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>5.843333</td>\n      <td>3.057333</td>\n      <td>3.758000</td>\n      <td>1.199333</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.828066</td>\n      <td>0.435866</td>\n      <td>1.765298</td>\n      <td>0.762238</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>4.300000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>0.100000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>5.100000</td>\n      <td>2.800000</td>\n      <td>1.600000</td>\n      <td>0.300000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5.800000</td>\n      <td>3.000000</td>\n      <td>4.350000</td>\n      <td>1.300000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6.400000</td>\n      <td>3.300000</td>\n      <td>5.100000</td>\n      <td>1.800000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>7.900000</td>\n      <td>4.400000</td>\n      <td>6.900000</td>\n      <td>2.500000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":14},{"cell_type":"markdown","source":["[example data](https://www.kaggle.com/c/bnp-paribas-cardif-claims-management/overview)"],"metadata":{}},{"cell_type":"markdown","source":["##Exploratory Data Analysis (EDA)\nEDA is all about understanding your data by employing summarizing and visualizing techniques. At a high level the EDA can be performed in two folds, that is, univariate analysis and multivariate analysis.\n\n###Univariate Analysis\nIndividual variables are analyzed in isolation to have a better understanding about them.\n\nPandas provide the describe function to create summary statistics in tabular format for all variables.\n\nThese statistics are very useful for numerical types of variables to understand any quality issues such as missing values and the presence of outliers."],"metadata":{}},{"cell_type":"code","source":["iris['species'].value_counts()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[3]: setosa        50\nversicolor    50\nvirginica     50\nName: species, dtype: int64</div>"]}}],"execution_count":17},{"cell_type":"code","source":["# Set the size of the plot\n#plt.figsize(15, 8)\niris.hist() # plot histogram\nplt.suptitle(\"Histogram\", fontsize=16) # use suptitle to add title to all\nsublots\nplt.show()"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["iris.boxplot() # plot boxplot\nplt.title(\"Bar Plot\", fontsize=16)\nplt.show()"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["###Multivariate Analysis\nIn multivariate analysis you try to establish a sense of relationship of all variables with one other."],"metadata":{}},{"cell_type":"code","source":["# print the mean for each column by species\niris.groupby(by = \"species\").mean()\n# plot for mean of each feature for each label class\niris.groupby(by = \"species\").mean().plot(kind=\"bar\")\nplt.title('Class vs Measurements')\nplt.ylabel('mean measurement(cm)')\nplt.xticks(rotation=0) # manage the xticks rotation\nplt.grid(True)\n# Use bbox_to_anchor option to place the legend outside plot area to be tidy\nplt.legend(loc=\"upper left\", bbox_to_anchor=(1,1))"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["###Correlation Matrix\nThe correlation function uses Pearson correlation coefficient, which results in a number between -1 to 1. A strong negative relationship is indicated by a coefficient closer to -1 and a strong positive correlation is indicated by a coefficient toward 1."],"metadata":{}},{"cell_type":"code","source":["# create correlation matrix\ncorr = iris.corr()\ncorr"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepallength(cm)</th>\n      <th>sepalwidth(cm)</th>\n      <th>petallength(cm)</th>\n      <th>petalwidth(cm)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>sepallength(cm)</th>\n      <td>1.000000</td>\n      <td>-0.117570</td>\n      <td>0.871754</td>\n      <td>0.817941</td>\n    </tr>\n    <tr>\n      <th>sepalwidth(cm)</th>\n      <td>-0.117570</td>\n      <td>1.000000</td>\n      <td>-0.428440</td>\n      <td>-0.366126</td>\n    </tr>\n    <tr>\n      <th>petallength(cm)</th>\n      <td>0.871754</td>\n      <td>-0.428440</td>\n      <td>1.000000</td>\n      <td>0.962865</td>\n    </tr>\n    <tr>\n      <th>petalwidth(cm)</th>\n      <td>0.817941</td>\n      <td>-0.366126</td>\n      <td>0.962865</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":23},{"cell_type":"code","source":["import statsmodels.api as sm\nsm.graphics.plot_corr(corr, xnames=list(corr.columns))\nplt.show()"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":["###Pair Plot\nYou can understand the relationship attributes by looking at the distribution of the interactions of each pair of attributes. This uses a built-in function to create a matrix of scatter plots of all attributes against all attributes."],"metadata":{}},{"cell_type":"markdown","source":["### Findings from EDA\n* There are no missing values.\n* Sepal is longer than petal. Sepal length ranges between 4.3 to 7.9 with average length of 5.8, whereas petal length ranges between 1 to 6.9 with average length of 3.7.\n* Sepal is also wider than petal. Sepal width ranges between 2 to 4.4 with a average width of 3.05, whereas petal width ranges between 0.1 to 2.5 with average width of 1.19.\n* Average petal length of setosa is much smaller than versicolor and virginica; however the average sepal width of setosa is higher than versicolor and virginica.\n* Petal length and width are strongly correlated, that is, 96% of the time width increases with increase in length.\n* Petal length has negative correlation with sepal width, that is, 42% of the time increase in sepal width will decrease petal length.\n* Initial conclusion from data: Based on length and width of sepal/ petal alone, you can conclude that versicolor/virginica might resemble in size; however setosa characteristics seem to be noticeably different from the other two."],"metadata":{}},{"cell_type":"code","source":["df = pd.read_csv('') "],"metadata":{},"outputs":[],"execution_count":27}],"metadata":{"name":"ML_Python_Chp1_EDA","notebookId":3884122347306837},"nbformat":4,"nbformat_minor":0}
